name: CI/CD for User Service

on:
  push:
    branches: [ "main" ]
    paths:
      - "user/**"
      - ".github/workflows/user-ci.yml"
      - "nomad/user.hcl"
      - "docker/Dockerfile.stage"
  pull_request:
    branches: [ "main" ]
    paths:
      - "user/**"
      - ".github/workflows/user-ci.yml"
      - "nomad/user.hcl"

env:
  IMAGE_TAG: ${{ github.ref_name }}-${{ github.sha }}
  DOCKER_IMAGE: friendy21/user-service
  SERVICE_NAME: user-service
  SERVICE_PORT: 5001

permissions:
  contents: read
  packages: write
  security-events: write

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.DOCKER_IMAGE }}
        tags: |
          type=ref,event=branch
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
        
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./user
        file: ./docker/Dockerfile.stage
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILD_DATE=${{ github.event.head_commit.timestamp }}
          VERSION=${{ env.IMAGE_TAG }}

    - name: Run security scan
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.DOCKER_IMAGE }}:latest
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v3
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  deploy:
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Nomad
      uses: hashicorp/setup-nomad@main
      with:
        nomad_version: 'latest'

    - name: Verify Nomad installation
      run: |
        echo "âœ… Nomad version:"
        nomad version
        echo "âœ… Nomad binary location:"
        which nomad

    - name: Deploy to Nomad
      env:
        NOMAD_ADDR: ${{ secrets.NOMAD_ADDR }}
        NOMAD_TOKEN: ${{ secrets.NOMAD_TOKEN }}
      run: |
        set -e
        
        echo "ðŸš€ Starting User Service deployment..."
        
        # Comprehensive environment validation
        if [ -z "$NOMAD_ADDR" ]; then
          echo "âŒ NOMAD_ADDR environment variable is required"
          exit 1
        fi
        
        if [ -z "$NOMAD_TOKEN" ]; then
          echo "âŒ NOMAD_TOKEN environment variable is required"
          exit 1
        fi
        
        echo "âœ… Environment variables validated"
        echo "ðŸŽ¯ Nomad Address: $NOMAD_ADDR"
        echo "ðŸ”§ Docker Image: ${{ env.DOCKER_IMAGE }}:${{ env.IMAGE_TAG }}"
        echo "ðŸ“¦ Service: ${{ env.SERVICE_NAME }}"
        echo "ðŸ”Œ Port: ${{ env.SERVICE_PORT }}"
        echo ""
        
        # Locate HCL file with fallback search
        HCL_FILE="nomad/user.hcl"
        if [ ! -f "$HCL_FILE" ]; then
          echo "âš ï¸ HCL file not found at expected location: $HCL_FILE"
          echo "ðŸ” Searching for user.hcl in repository..."
          
          FOUND_HCL=$(find . -name "user.hcl" -type f | head -1)
          if [ -n "$FOUND_HCL" ]; then
            HCL_FILE="$FOUND_HCL"
            echo "âœ… Found HCL file at: $HCL_FILE"
          else
            echo "âŒ user.hcl not found anywhere in repository"
            echo "ðŸ“ Available HCL files:"
            find . -name "*.hcl" -type f | head -10 || echo "No HCL files found"
            exit 1
          fi
        else
          echo "âœ… Using HCL file: $HCL_FILE"
        fi
        
        # Create timestamped backup
        BACKUP_FILE="${HCL_FILE}.backup.$(date +%s)"
        if ! cp "$HCL_FILE" "$BACKUP_FILE"; then
          echo "âŒ Failed to create backup file"
          exit 1
        fi
        echo "ðŸ’¾ Backup created: $BACKUP_FILE"
        
        # Display original file snippet
        echo "ðŸ“„ Original HCL content preview:"
        echo "----------------------------------------"
        head -15 "$HCL_FILE"
        echo "----------------------------------------"
        
        # Replace placeholders with comprehensive error handling
        echo "ðŸ”„ Replacing placeholders in HCL file..."
        
        # Check if placeholders exist before replacement
        IMAGE_PLACEHOLDERS=$(grep -c "IMAGE_TAG_PLACEHOLDER" "$HCL_FILE" || echo "0")
        DOCKER_PLACEHOLDERS=$(grep -c "DOCKER_IMAGE_PLACEHOLDER" "$HCL_FILE" || echo "0")
        
        echo "ðŸ“Š Found placeholders: IMAGE_TAG($IMAGE_PLACEHOLDERS), DOCKER_IMAGE($DOCKER_PLACEHOLDERS)"
        
        if [ "$IMAGE_PLACEHOLDERS" -eq 0 ] && [ "$DOCKER_PLACEHOLDERS" -eq 0 ]; then
          echo "âš ï¸ No placeholders found - file may already be processed or corrupted"
          echo "ðŸ“„ Current file content:"
          cat "$HCL_FILE"
          exit 1
        fi
        
        # Perform replacements
        if ! sed -i "s|IMAGE_TAG_PLACEHOLDER|${{ env.IMAGE_TAG }}|g" "$HCL_FILE"; then
          echo "âŒ Failed to replace IMAGE_TAG_PLACEHOLDER"
          cp "$BACKUP_FILE" "$HCL_FILE"
          exit 1
        fi
        
        if ! sed -i "s|DOCKER_IMAGE_PLACEHOLDER|${{ env.DOCKER_IMAGE }}|g" "$HCL_FILE"; then
          echo "âŒ Failed to replace DOCKER_IMAGE_PLACEHOLDER"
          cp "$BACKUP_FILE" "$HCL_FILE"
          exit 1
        fi
        
        # Verify all placeholders were replaced
        REMAINING_PLACEHOLDERS=$(grep -c "PLACEHOLDER" "$HCL_FILE" || echo "0")
        if [ "$REMAINING_PLACEHOLDERS" -gt 0 ]; then
          echo "âŒ $REMAINING_PLACEHOLDERS placeholders still remain:"
          grep -n "PLACEHOLDER" "$HCL_FILE" || true
          echo ""
          echo "ðŸ“„ Current file state:"
          cat "$HCL_FILE"
          echo ""
          echo "ðŸ”„ Restoring from backup..."
          cp "$BACKUP_FILE" "$HCL_FILE"
          exit 1
        fi
        
        echo "âœ… All placeholders successfully replaced"
        
        # Show key lines from processed file
        echo "ðŸ“„ Processed HCL - key configuration:"
        echo "----------------------------------------"
        grep -E "(job |image.*=|SERVICE_)" "$HCL_FILE" | head -8
        echo "----------------------------------------"
        
        # Test Nomad connectivity with retries
        echo "ðŸ”— Testing Nomad connectivity..."
        MAX_CONN_RETRIES=5
        CONN_RETRY=0
        
        while [ $CONN_RETRY -lt $MAX_CONN_RETRIES ]; do
          if nomad node status >/dev/null 2>&1; then
            echo "âœ… Successfully connected to Nomad cluster"
            
            # Get cluster info
            NODE_COUNT=$(nomad node status -json 2>/dev/null | jq length 2>/dev/null || echo "unknown")
            echo "ðŸ“Š Cluster nodes: $NODE_COUNT"
            break
          fi
          
          CONN_RETRY=$((CONN_RETRY + 1))
          if [ $CONN_RETRY -lt $MAX_CONN_RETRIES ]; then
            echo "â³ Connection attempt $CONN_RETRY/$MAX_CONN_RETRIES failed, retrying in 10s..."
            sleep 10
          else
            echo "âŒ Failed to connect to Nomad after $MAX_CONN_RETRIES attempts"
            echo "ðŸ” Attempting to get Nomad server info..."
            curl -s --max-time 10 "$NOMAD_ADDR/v1/status/leader" || echo "Unable to reach Nomad API"
            exit 1
          fi
        done
        
        # Validate job configuration
        echo "ðŸ” Validating Nomad job configuration..."
        if ! nomad job validate "$HCL_FILE"; then
          echo "âŒ Job validation failed"
          echo ""
          echo "ðŸ“„ Full HCL file content for debugging:"
          echo "========================================"
          cat "$HCL_FILE"
          echo "========================================"
          exit 1
        fi
        echo "âœ… Job configuration is valid"
        
        # Create deployment plan
        echo "ðŸ“‹ Generating deployment plan..."
        if nomad job plan "$HCL_FILE" >/dev/null 2>&1; then
          echo "âœ… Deployment plan generated successfully"
        else
          echo "âš ï¸ Deployment planning completed with warnings (this is often normal)"
        fi
        
        # Execute deployment
        echo "ðŸš€ Executing User Service deployment..."
        if ! nomad job run "$HCL_FILE"; then
          echo "âŒ Failed to submit job to Nomad"
          echo "ðŸ“Š Attempting to get current job status:"
          nomad job status ${{ env.SERVICE_NAME }} 2>/dev/null || echo "No existing job found"
          exit 1
        fi
        echo "âœ… Job successfully submitted to Nomad cluster"
        
        # Enhanced deployment monitoring
        echo "â³ Monitoring deployment progress..."
        echo "ðŸ“Š This may take several minutes for initial deployment"
        
        MAX_WAIT_CYCLES=120  # 10 minutes total
        WAIT_CYCLE=0
        CONSECUTIVE_RUNNING=0
        LAST_REPORTED_STATUS=""
        
        while [ $WAIT_CYCLE -lt $MAX_WAIT_CYCLES ]; do
          # Get comprehensive status
          JOB_STATUS=$(nomad job status ${{ env.SERVICE_NAME }} 2>/dev/null)
          CURRENT_STATUS=$(echo "$JOB_STATUS" | grep "^Status" | awk '{print $3}' 2>/dev/null || echo "checking")
          
          # Report status changes
          if [ "$CURRENT_STATUS" != "$LAST_REPORTED_STATUS" ]; then
            echo "ðŸ“Š Status change: $LAST_REPORTED_STATUS â†’ $CURRENT_STATUS (cycle $((WAIT_CYCLE + 1))/$MAX_WAIT_CYCLES)"
            LAST_REPORTED_STATUS="$CURRENT_STATUS"
            CONSECUTIVE_RUNNING=0
            
            # Show additional details on status change
            if [ "$CURRENT_STATUS" != "running" ]; then
              echo "$(echo "$JOB_STATUS" | head -8)"
            fi
          fi
          
          case "$CURRENT_STATUS" in
            "running")
              CONSECUTIVE_RUNNING=$((CONSECUTIVE_RUNNING + 1))
              
              # Require stable running state
              if [ $CONSECUTIVE_RUNNING -ge 6 ]; then
                echo "âœ… User Service is running stably!"
                
                # Display comprehensive deployment summary
                echo ""
                echo "ðŸ“Š Final Deployment Summary:"
                echo "==========================================="
                echo "$JOB_STATUS" | head -18
                echo "==========================================="
                
                # Enhanced health check with multiple attempts
                echo ""
                echo "ðŸ¥ Performing comprehensive health verification..."
                HEALTH_CHECK_SUCCESS=false
                
                for health_attempt in {1..10}; do
                  echo "ðŸ”„ Health check attempt $health_attempt/10..."
                  
                  # Try multiple health check approaches
                  for health_endpoint in "http://localhost:${{ env.SERVICE_PORT }}/health" "http://127.0.0.1:${{ env.SERVICE_PORT }}/health"; do
                    if timeout 15 curl -f -s "$health_endpoint" >/dev/null 2>&1; then
                      echo "âœ… Health check successful via $health_endpoint"
                      
                      # Get detailed health information
                      HEALTH_RESPONSE=$(timeout 10 curl -s "$health_endpoint" 2>/dev/null)
                      if echo "$HEALTH_RESPONSE" | jq . >/dev/null 2>&1; then
                        echo "ðŸ“‹ Service Health Details:"
                        echo "$HEALTH_RESPONSE" | jq .
                      else
                        echo "ðŸ“‹ Health endpoint responded: $HEALTH_RESPONSE"
                      fi
                      
                      HEALTH_CHECK_SUCCESS=true
                      break 2
                    fi
                  done
                  
                  # Progressive delay between attempts
                  if [ $health_attempt -lt 10 ]; then
                    DELAY=$((health_attempt * 2 + 5))
                    echo "â³ Waiting ${DELAY}s before next attempt..."
                    sleep $DELAY
                  fi
                done
                
                if [ "$HEALTH_CHECK_SUCCESS" = false ]; then
                  echo "âš ï¸ Health endpoint verification failed"
                  echo "ðŸ” This may be normal if:"
                  echo "   â€¢ Service is still initializing"
                  echo "   â€¢ Network policies restrict access"
                  echo "   â€¢ Health endpoint is not implemented"
                  echo ""
                  echo "ðŸ“Š Service appears to be running based on Nomad status"
                fi
                
                # Final success message
                echo ""
                echo "ðŸŽ‰ User Service deployment completed successfully!"
                echo "ðŸŒ Service should be accessible at: http://localhost:${{ env.SERVICE_PORT }}"
                echo "ðŸ“Š Monitor via Nomad UI: $NOMAD_ADDR/ui/jobs/${{ env.SERVICE_NAME }}"
                
                exit 0
              else
                echo "ðŸ“Š Running state stable for ${CONSECUTIVE_RUNNING}/6 cycles"
              fi
              ;;
            "dead"|"failed")
              echo "âŒ Deployment failed with status: $CURRENT_STATUS"
              echo ""
              echo "ðŸ“Š Detailed failure analysis:"
              echo "==========================================="
              echo "$JOB_STATUS"
              echo "==========================================="
              echo ""
              echo "ðŸ“‹ Recent allocations:"
              nomad job allocs ${{ env.SERVICE_NAME }} 2>/dev/null | head -8 || echo "No allocation data available"
              echo ""
              echo "ðŸ“ Recent logs from failed allocation:"
              FAILED_ALLOC=$(nomad job allocs ${{ env.SERVICE_NAME }} -json 2>/dev/null | jq -r '.[0].ID' 2>/dev/null)
              if [ -n "$FAILED_ALLOC" ] && [ "$FAILED_ALLOC" != "null" ]; then
                nomad alloc logs -n 40 "$FAILED_ALLOC" 2>/dev/null || echo "Logs not available"
              else
                echo "No allocation logs available"
              fi
              
              exit 1
              ;;
            "pending")
              # Detailed progress info every 20 cycles (reduce log noise)
              if [ $((WAIT_CYCLE % 20)) -eq 0 ] && [ $WAIT_CYCLE -gt 0 ]; then
                echo "ðŸ“Š Still pending after $((WAIT_CYCLE * 5)) seconds..."
                echo "$(echo "$JOB_STATUS" | head -10)"
                
                # Check for allocation issues
                ALLOC_COUNT=$(nomad job allocs ${{ env.SERVICE_NAME }} -json 2>/dev/null | jq length 2>/dev/null || echo "0")
                echo "ðŸ“‹ Current allocations: $ALLOC_COUNT"
              fi
              ;;
            *)
              CONSECUTIVE_RUNNING=0
              # Log unknown statuses
              if [ "$CURRENT_STATUS" != "checking" ]; then
                echo "âš ï¸ Unknown status: $CURRENT_STATUS"
              fi
              ;;
          esac
          
          sleep 5
          WAIT_CYCLE=$((WAIT_CYCLE + 1))
        done
        
        # Deployment monitoring timeout
        echo "âŒ Deployment monitoring timed out after $((MAX_WAIT_CYCLES * 5)) seconds"
        echo ""
        echo "ðŸ“Š Final status report:"
        echo "==========================================="
        nomad job status ${{ env.SERVICE_NAME }} 2>/dev/null || echo "Unable to get job status"
        echo "==========================================="
        echo ""
        echo "ðŸ“‹ Final allocation status:"
        nomad job allocs ${{ env.SERVICE_NAME }} 2>/dev/null || echo "Unable to get allocation status"
        
        exit 1
